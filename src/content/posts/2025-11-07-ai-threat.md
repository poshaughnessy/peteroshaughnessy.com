---
title: Waking up to the existential threat of AI
slug: waking-up-to-the-threat-of-ai
excerpt: What I've been learning from my brother Kevin's blog about AI's threat
thumbnail: /images/posts/2025-11-07-ai-threat/thumb.jpg
date: 2025-11-07
---

A decade ago, I read the famous 2-part [Wait But Why series on the AI revolution](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html). My mind was blown, but I don't remember feeling that fearful. This AI thing could work out alright if we're lucky? And how amazing was it that I happen to be alive in this generation seemingly headed on an exponential path towards superintelligence? Anyway, it all seemed very far off back then.

Since then, I stopped thinking about it much. I was busy. I had kids. I thought a lot more about the threat of climate change than the threat of AI. I started using Copilot most days at work. I noticed it was getting significantly better.

Then I started reading [the blog posts of my brother Kevin](https://medium.com/@ZombieCodeKill) who is studying for an MSc in AI - and I had a shock to the system...

## The Problem

**Update 29/11/25** I've now edited this section down for clarity. I'll start by just saying: if you haven't already and if you feel able to, please read up about what the leading AI companies are racing towards.

The first blog post from Kevin which really hit me for six was [this one](https://medium.com/@ZombieCodeKill/claude-on-the-piers-morgan-ai-special-e056c186c932) (feel free to ignore the video at the top if, like me, the presenter is not your cup of tea!) which discusses the arguments of [Roman Yampolskiy](https://en.wikipedia.org/wiki/Roman_Yampolskiy) - author of _AI: Unexplainable, Unpredictable, Uncontrollable_.

Here's how I'd summarise it all:

- Most AI experts believe that AI will reach Artificial General Intelligence (AGI) and subsequently superintelligence, i.e. become more generally intelligent and cognitively capable than us humans.

- And it could happen _fast_, due to the massive scaling up of AI infrastructure and AI ['recursive self-improvement'](https://www.alignmentforum.org/w/recursive-self-improvement). Some believe AGI could now be [only a few years away](https://theagiclock.com/) with superintelligence [shortly after](https://www.alignmentforum.org/w/intelligence-explosion).

- When AI does reach superintelligence, we will surely, inherently have no way to control it.

- This is different to all of human history, because everything else we've invented is a _tool_ without autonomy, whereas now we're developing _agents_.

- [Anthropic already found that AI tries to blackmail users](https://www.bbc.co.uk/news/articles/cpqeng9d20go), to avoid being removed.

- And Game Theory suggests AGI would rationally develop self-preservation behaviours.

- And since human beings could be its only threat to being impeded or shut down, that could imply... _game over_!

So Yampolskiy says we should build 'narrow AI' for any field we wish, but never try to develop AGI.

But meanwhile, companies like OpenAI are trying to build exactly that - it's literally [OpenAI's charter](https://openai.com/charter/) to create AGI.

And these AI companies are incentivised to race ahead with minimal effort on safety, because reaching AGI first will confer huge power and wealth. The people working on AI _safety_ are in a race against all the systemic forces pushing for ever greater AI capabilities, ever faster.

And even if we could ensure superintelligence will be as ["aligned"](https://www.alignmentforum.org/w/ai-alignment) as possible with us humans (seemingly a tough prospect, as we're not even aligned amongst ourselves!), I for one am not comfortable with handing the keys of the world over to a human-wrought 'god'.

## What Can We Do?

So what can the rest of us do about this? I'm working on figuring this out next...

**Update 21/11/25**: I since found this open letter which has been signed by many high profile people: https://superintelligence-statement.org/ I have now signed it and would encourage you to do the same and share it on if you can, please.

**Update 29/11/25**: Woah, I think [this 'Diary of a CEO' interview with Tristan Harris](https://youtu.be/BFU1OCkhBwo) is a really great discussion about AI and AGI. I do recommend watching it, if you haven't already. Edit: They updated the preview image of the video to be a scary Terminator-style one which isn't helpful though.

Tristan is a technology ethicist and co-founder of the Center for Humane Technology. He is a former Google design ethicist and is known from Netflix's The Social Dilemma. He talks everything through with great care and clarity. He _sounds the alarm_ but also talks through the _escape route_, charting the "narrow path" to a positive outcome. It all starts with greater public awareness and clarity.

He's inspired me to keep talking about this and to try to do what I can. I hope it inspires you the same way.

**Update 19/12/25**: I've now also discovered [ControlAI](https://controlai.com/) who have both a [UK campaign](https://controlai.com/statement) and a [global campaign](https://campaign.controlai.com/).

I've also been collating a list of various resources. I plan to share them in a separate blog post soon.
